### 文字前處理類需求分析開發思路

**目標：**
明確下游模型（如 CLIP、BERT 等）所需的文字前處理步驟，為後續實作 CLIPTextTokenizer 等類別打下基礎。

---

#### 開發思路

1. **確認下游模型需求**
   - 查閱 CLIP、BERT 等模型的官方文件或現有實作，了解其輸入格式（如 token ids、attention mask、特殊 token）。
   - 釐清模型是否有固定詞彙表（vocab）、最大長度（max_length）、padding 方式、特殊符號（如 [CLS]、[SEP]）。

   - 本階段需支援的下游模型為 OPENCLIP。
   - 主要文字前處理需求如下：
   1. 使用 OPENCLIP 官方 tokenizer（如 SimpleTokenizer）或 HuggingFace 的 tokenizer 作為文字前處理工具。
   2. 輸入格式為 List[str]，支援批次處理。
   3. 前處理步驟包含：
      - 分詞（tokenize）：將文字切分為 token。
      - 轉 index：將 token 轉為對應詞彙表的 index（token id）。
      - Padding：將 index 序列補齊到固定長度（如 max_length，OPENCLIP 預設為 77）。
      - Attention mask：標記哪些位置是有效 token（1）或 padding（0）。
      - 處理特殊字元：根據模型需求加上特殊 token（如 [SOS]、[EOS] 或 [SEP]）。
   4. 詞彙表（vocab）可直接使用 OPENCLIP 或 HuggingFace 官方提供的詞彙表與 tokenizer 工具。

   **結論：**
   - 目前需求明確，後續可依據上述規格設計與實作 CLIPTextTokenizer，並確保與 OPENCLIP 模型對接無縫。

2. **整理前處理步驟**
   - 分詞（tokenize）：將輸入文字切分為 token。
   - 轉 index：將 token 轉為對應的詞彙表索引（token ids）。
   - Padding：將序列補齊到固定長度（如 max_length）。
   - 產生 attention mask：標記哪些位置是有效 token。
   - 處理特殊 token：如開頭/結尾需加 [CLS]、[SEP] 等。

   **目標：**
   明確每一步文字前處理的細節，確保後續實作能與 OPENCLIP 模型需求完全對齊。

   #### 步驟說明

   2.1. **分詞（tokenize）**
      - 將輸入的每個字串切分為 token。
      - 依據 OPENCLIP 的 tokenizer（如 SimpleTokenizer）進行分詞，確保與官方詞彙表一致。

   2.2. **轉 index（token to token ids）**
      - 將分詞後的 token 轉換為對應詞彙表的 index（token id）。
      - 若遇到未知詞，需依 tokenizer 規則處理（如用 [UNK] 或特殊 id）。

   2.3. **Padding**
      - 將每個 token id 序列補齊到固定長度（如 max_length，OPENCLIP 預設為 77）。
      - 不足長度時補 0 或指定 padding id，超過時截斷。

   2.4. **產生 attention mask**
      - 產生與 token id 序列等長的 mask，標記哪些位置是有效 token（1），哪些是 padding（0）。

   5. **處理特殊 token**
      - 根據模型需求，在序列開頭/結尾加上特殊 token（如 [SOS]、[EOS]、[SEP] 等）。
      - 確認特殊 token 的 id 並正確插入。

---

**備註：**
- 若使用 HuggingFace tokenizer，以上步驟多可自動完成（建議用 `padding=True, truncation=True, return_attention_mask=True`）。
- 若用 OPENCLIP SimpleTokenizer，需手動處理 padding、mask 與特殊 token。

---

3. **彙整需求為接口設計**
   - 輸入：原始文字（str 或 List[str]）
   - 輸出：token ids（List[int] 或 tensor）、attention mask、（可選）token type ids

   **目標：**
   設計一個統一且易於擴展的前處理類接口，能支援 str 或 List[str] 輸入，並回傳 token ids、attention mask（可選 token type ids）。

   ---

   #### 步驟說明

   1. **定義類別與初始化參數**
      - 設計一個前處理類（如 `OpenCLIPTextTokenizer`）。
      - 初始化時設定 tokenizer、max_length、pad_token_id 等參數。

   2. **設計統一接口（如 `__call__` 方法）**
      - 支援輸入為 str 或 List[str]。
      - 支援參數：padding、truncation、max_length、return_attention_mask、return_tensors。

   3. **實作前處理主流程**
      - 將輸入轉為 List[str]。
      - 逐句分詞並轉換為 token ids。
      - 根據 max_length 做 padding 或截斷。
      - 產生 attention mask（1=有效，0=padding）。
      - （可選）產生 token type ids（如有需要）。

   4. **組裝與回傳結果**
      - 組裝為 dict，包含 input_ids、attention_mask（可選 token_type_ids）。
      - 根據 return_tensors 參數，回傳 list、numpy 或 torch tensor 格式。

   5. **單元測試與範例**
      - 撰寫測試，驗證單句與多句輸入、不同 padding/truncation/max_length 等情境。
      - 提供簡單的使用範例。

   ---

4. **確認現有工具鏈**
   - 是否可直接利用 HuggingFace Tokenizer、CLIP 官方 tokenizer 等現成工具？
   - 是否需自訂詞彙表或特殊規則？

---

#### 建議產出

- 一份「CLIP/BERT 文字前處理需求說明」文件，列出所有步驟與格式要求。
- 初步接口設計草稿（如 `__call__(text: str) -> Dict[str, Any]`）。
- 若有特殊需求（如多語言、特殊符號處理），一併記錄。

---

如需範例需求說明或接口設計模板，請告知！